import os
import requests
from bs4 import BeautifulSoup

"""
ğŸ“„ get_img.py

ğŸ”¹ ÙˆØ¸ÙŠÙØ© Ø§Ù„Ù…Ù„Ù:
ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ± Ù…Ù† ØµÙØ­Ø§Øª ÙˆÙŠØ¨ Ù…Ø®ØªÙ„ÙØ© Ø¨Ø´ÙƒÙ„ Ø£ÙØ¶Ù„ Ù…Ù† `dwonload_img_from_page_web.py`.

ğŸ’¡ Ù…Ù†Ø§Ø³Ø¨ Ø£ÙƒØ«Ø± Ù„Ù„Ù…ÙˆØ§Ù‚Ø¹ Ø§Ù„ØªÙŠ Ø¨Ù‡Ø§ ØªÙ†Ø³ÙŠÙ‚Ø§Øª Ù…Ø®ØªÙ„ÙØ© Ø£Ùˆ Ø£ÙƒØ«Ø± Ø­Ù…Ø§ÙŠØ©.
"""


# ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø±Ø§Ø¨Ø· Ø§Ù„Ø°ÙŠ ØªØ±ÙŠØ¯ Ø§Ù„Ø¨Ø­Ø« ÙÙŠÙ‡
url = "https//examle.com"  # Ø§Ø³ØªØ¨Ø¯Ù„Ù‡ Ø¨Ø§Ù„Ø±Ø§Ø¨Ø· Ø§Ù„Ø°ÙŠ ØªØ±ÙŠØ¯ Ø§Ù„Ø¨Ø­Ø« ÙÙŠÙ‡

# Ø¥Ø±Ø³Ø§Ù„ Ø·Ù„Ø¨ GET Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù…Ø­ØªÙˆÙ‰ Ø§Ù„ØµÙØ­Ø©
response = requests.get(url)

# Ø§Ø³ØªØ®Ø¯Ø§Ù… BeautifulSoup Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø­ØªÙˆÙ‰
soup = BeautifulSoup(response.text, 'html.parser')

# Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø¬Ù…ÙŠØ¹ Ø§Ù„ØµÙˆØ± ÙÙŠ Ø§Ù„ØµÙØ­Ø©
images = soup.find_all('img')
folder = "Indecent2"
# Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¬Ù„Ø¯ Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„ØµÙˆØ±
if not os.path.exists(folder):
    os.makedirs(folder)

# ØªÙ†Ø²ÙŠÙ„ Ø§Ù„ØµÙˆØ±
for img in images:
    img_url = img.get('src')
    if img_url:
        # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Ø±Ø§Ø¨Ø· Ø§Ù„ØµÙˆØ±Ø© ÙƒØ§Ù…Ù„
        if not img_url.startswith('http'):
            img_url = url + img_url
        # Ø¥Ø±Ø³Ø§Ù„ Ø·Ù„Ø¨ Ù„ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø©
        img_data = requests.get(img_url).content
        # Ø­ÙØ¸ Ø§Ù„ØµÙˆØ±Ø© ÙÙŠ Ø§Ù„Ù…Ø¬Ù„Ø¯
        img_name = os.path.join('downloaded_images', os.path.basename(img_url))
        with open(img_name, 'wb') as f:
            f.write(img_data)
        print(f"ØªÙ… ØªÙ†Ø²ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø©: {img_name} : Ø±Ù‚Ù… {images.index(img) + 1}")
